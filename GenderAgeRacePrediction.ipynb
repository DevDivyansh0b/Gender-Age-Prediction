{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e57710c",
   "metadata": {},
   "source": [
    "# Install dependencies and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f57724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\whyis\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\whyis\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\whyis\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\whyis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d347ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\whyis\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1845c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid OOM erros by setting GPU Memory Consumption\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56c9dc08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import imghdr\n",
    "data_dir='data'\n",
    "image_exts=['jpeg','jpg','bmp','png']\n",
    "for image in os.listdir(data_dir):\n",
    "    image_path=os.path.join(data_dir,image)\n",
    "    try:\n",
    "        img=cv2.imread(image_path)\n",
    "        tip=imghdr.what(image_path)\n",
    "        if tip not in image_exts:\n",
    "            print(\"Image extension not in list \",image_exts)\n",
    "            os.remove(image_path)\n",
    "        if (os.path.getsize(image_path)/1024)<10:\n",
    "            print(\"Size of image is less than 10KB \",image_exts)\n",
    "            os.remove(image_path)\n",
    "    except:\n",
    "        print(\"Issue with image \",image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a5a55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List to store data\n",
    "data = []\n",
    "# Iterate through the image files\n",
    "for filename in os.listdir(data_dir):\n",
    "    try:\n",
    "        # Extract information from the filename\n",
    "        age, sex, race, _ = filename.split('_')\n",
    "        # Convert strings to appropriate data types\n",
    "        age = int(age)\n",
    "        sex = int(sex)\n",
    "        race = int(race)\n",
    "\n",
    "        # Append the data as a tuple\n",
    "        data.append((filename, age, sex, race))\n",
    "    except:\n",
    "        print(\"Issue with image \",filename)\n",
    "        os.remove(os.path.join(data_dir,filename))\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "df = pd.DataFrame(data, columns=['Filename', 'Age', 'Sex', 'Race'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "df.to_csv('Image_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84845edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b8361",
   "metadata": {},
   "source": [
    "# Performing data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d14d6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import albumentations as abl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "589375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset into a Pandas DataFrame\n",
    "df = pd.read_csv(os.path.join('Image_dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "291eaf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory where augmented images will be saved\n",
    "output_dir = os.path.join('augmented_data')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ecae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation pipeline using Albumentations\n",
    "augmentation_pipeline = abl.Compose([\n",
    "    abl.HorizontalFlip(p=0.5),\n",
    "    abl.RandomBrightnessContrast(p=0.2),\n",
    "    abl.RandomBrightnessContrast(p=0.2),\n",
    "    abl.RandomGamma(p=0.2),\n",
    "    abl.RGBShift(p=0.2),\n",
    "    abl.VerticalFlip(p=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b5717e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply augmentation to each image\n",
    "def augment_and_save(image_path, output_dir):\n",
    "    try:\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply augmentation\n",
    "        augmented = augmentation_pipeline(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "\n",
    "        # Extract file name and extension\n",
    "        file_name = os.path.basename(image_path)\n",
    "        base_name, extension = os.path.splitext(file_name)\n",
    "\n",
    "        # Save the augmented image\n",
    "        output_path = os.path.join(output_dir, f'{base_name}_augmented{extension}')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "    except:\n",
    "        print(\"some issue with file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86f1070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to each image in the dataset\n",
    "for index, row in df.iterrows():\n",
    "    image_path = os.path.join(data_dir,row['Filename'])\n",
    "    augment_and_save(image_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7604ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store augmented data\n",
    "augmented_data = []\n",
    "augmented_data_dir='augmented_data'\n",
    "# Iterate through the image files\n",
    "for filename in os.listdir(augmented_data_dir):\n",
    "    try:\n",
    "        # Extract information from the filename\n",
    "        age, sex, race, _,__ = filename.split('_')\n",
    "        # Convert strings to appropriate data types\n",
    "        age = int(age)\n",
    "        sex = int(sex)\n",
    "        race = int(race)\n",
    "\n",
    "        # Append the data as a tuple\n",
    "        augmented_data.append((filename, age, sex, race))\n",
    "    except:\n",
    "        print(\"Issue with image \",filename)\n",
    "        os.remove(os.path.join(data_dir,filename))\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "augmented_df = pd.DataFrame(augmented_data, columns=['Filename', 'Age', 'Sex', 'Race'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "augmented_df.head()\n",
    "augmented_df.to_csv('augmented_Image_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd4e919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a full dataset consisting of both original and augmented data\n",
    "os.makedirs('full_data', exist_ok=True)\n",
    "for filename in os.listdir('data'):\n",
    "    try:\n",
    "        image_path=os.path.join('data',filename)\n",
    "        image=cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            output_path = os.path.join('full_data',filename)\n",
    "            cv2.imwrite(output_path,image)\n",
    "    except Exception as e:\n",
    "        print(\"Issue with image \",filename,\" \",e)\n",
    "        \n",
    "for filename in os.listdir('augmented_data'):\n",
    "    try:\n",
    "        image_path=os.path.join('augmented_data',filename)\n",
    "        image=cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            output_path = os.path.join('full_data',filename)\n",
    "            cv2.imwrite(output_path,image)\n",
    "    except Exception as e:\n",
    "        print(\"Issue with image \",filename,\" \",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59088107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store resized data\n",
    "resized_data = []\n",
    "resized_data_dir='full_data'\n",
    "# Iterate through the image files\n",
    "for filename in os.listdir(resized_data_dir):\n",
    "    try:\n",
    "        # Extract information from the filename\n",
    "        if len(filename.split('_'))==5:\n",
    "            age, sex, race, _,__ = filename.split('_')\n",
    "        else:\n",
    "            age, sex, race, _ = filename.split('_')\n",
    "        # Convert strings to appropriate data types\n",
    "        age = int(age)\n",
    "        sex = int(sex)\n",
    "        race = int(race)\n",
    "\n",
    "        # Append the data as a tuple\n",
    "        resized_data.append((filename, age, sex, race))\n",
    "    except:\n",
    "        print(\"Issue with image \",filename)\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "resized_df = pd.DataFrame(resized_data, columns=['Filename', 'Age', 'Sex', 'Race'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "resized_df.head()\n",
    "resized_df.to_csv('resized_full_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a841c6",
   "metadata": {},
   "source": [
    "# Resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0b45adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3b44269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aecc3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing your images\n",
    "images_dir = 'full_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cec376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new directory to save resized images\n",
    "resized_images_dir = 'resized_full_data'\n",
    "os.makedirs(resized_images_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d7939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file containing image paths\n",
    "df = pd.read_csv('resized_full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f97d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and save images\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(images_dir, row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            # Resize the image to 224x224\n",
    "            img_resized = cv2.resize(img, (224, 224))\n",
    "            # Save the resized image to the new directory\n",
    "            new_image_path = os.path.join(resized_images_dir, row['Filename'])\n",
    "            cv2.imwrite(new_image_path, img_resized)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423dec6",
   "metadata": {},
   "source": [
    "# Scaling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ff7aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('resized_full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f41d8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the pixel values by dividing them by 255\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = image / 255.0  # Scale pixel values\n",
    "            return image\n",
    "        else:\n",
    "            print(f\"Error: Unable to read image at path {image_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59e26c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Image'] = df['Filename'].apply(lambda x: preprocess_image(os.path.join('resized_full_data',x)))\n",
    "# Filter out rows with None (failed to load image)   \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "617d6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6acf91",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56f34c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66f540c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0a85d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age labels (regression)\n",
    "scaler = StandardScaler()\n",
    "train_age_labels = scaler.fit_transform(train_df['Age'].values.reshape(-1, 1))\n",
    "val_age_labels = scaler.transform(val_df['Age'].values.reshape(-1, 1))\n",
    "test_age_labels = scaler.transform(test_df['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30b50631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex labels (binary classification)\n",
    "train_sex_labels = label_encoder.fit_transform(train_df['Sex'])\n",
    "val_sex_labels = label_encoder.transform(val_df['Sex'])\n",
    "test_sex_labels = label_encoder.transform(test_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf5a0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race labels (multiclass classification)\n",
    "train_race_labels = label_encoder.fit_transform(train_df['Race'])\n",
    "val_race_labels = label_encoder.transform(val_df['Race'])\n",
    "test_race_labels = label_encoder.transform(test_df['Race'])\n",
    "\n",
    "train_race_labels_one_hot = to_categorical(train_race_labels, num_classes=5)\n",
    "val_race_labels_one_hot = to_categorical(val_race_labels, num_classes=5)\n",
    "test_race_labels_one_hot = to_categorical(test_race_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69a3ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "baadc84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a919c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers for each output\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='relu', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0952b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Age Labels:\", train_age_labels.shape, train_age_labels.dtype)\n",
    "print(\"Train Sex Labels:\", train_sex_labels.shape, train_sex_labels.dtype)\n",
    "print(\"Train Race Labels:\", train_race_labels_one_hot.shape, train_race_labels_one_hot.dtype)\n",
    "\n",
    "print(\"Validation Age Labels:\", val_age_labels.shape, val_age_labels.dtype)\n",
    "print(\"Validation Sex Labels:\", val_sex_labels.shape, val_sex_labels.dtype)\n",
    "print(\"Validation Race Labels:\", val_race_labels_one_hot.shape, val_race_labels_one_hot.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d218321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Age Labels: NaN count -\", np.isnan(train_age_labels).sum())\n",
    "print(\"Validation Age Labels: NaN count -\", np.isnan(val_age_labels).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64db7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df['Filename'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a1acce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "import numpy as np\n",
    "# Load and preprocess the images\n",
    "X = []\n",
    "for index, row in train_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X = np.array(X)\n",
    "\n",
    "#for val set\n",
    "X_val = []\n",
    "for index, row in val_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X_val.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "history = model.fit(\n",
    "    X,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213b5a4",
   "metadata": {},
   "source": [
    "# Plotting loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4fb6b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "User\n",
    "Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\whyis\\\\anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
    "Consider using the `--user` option or check the permissions.\n",
    "\n",
    "i am trying to install albumentations library in jupyter notebook and this error comes when I run: !pip install albumentations, how to solve this?\n",
    "ChatGPT\n",
    "The error you're encountering indicates that there are permission issues when trying to install the albumentations library, specifically with the cv2.pyd file in the OpenCV package. Here are a few steps you can take to resolve the issue:\n",
    "\n",
    "Run Jupyter Notebook as Administrator:\n",
    "Try running Jupyter Notebook as an administrator to ensure that you have the necessary permissions to install packages. Right-click on the Jupyter Notebook shortcut and select \"Run as administrator.\" Then, try running the installation command again.\n",
    "\n",
    "Use --user Option:\n",
    "As the error message suggests, you can try using the --user option with the pip install command. This installs the package only for the current user and may bypass permission issues. Run the following command:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!pip install --user albumentations\n",
    "Check Folder Permissions:\n",
    "Make sure that you have the necessary permissions to write to the Lib\\site-packages folder. You can check and adjust the permissions manually if needed.\n",
    "\n",
    "Install in a Virtual Environment:\n",
    "Consider creating a virtual environment using venv or conda and installing the albumentations library within that environment. Virtual environments provide isolated environments for your projects and can help avoid conflicts with system-wide installations.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Create a virtual environment\n",
    "python -m venv myenv\n",
    "\n",
    "# Activate the virtual environment\n",
    "source myenv/bin/activate  # On Linux/Mac\n",
    "myenv\\Scripts\\activate     # On Windows\n",
    "\n",
    "# Install albumentations within the virtual environment\n",
    "pip install albumentations\n",
    "Check Antivirus Software:\n",
    "Some antivirus software may interfere with the installation process. Temporarily disabling your antivirus software (if applicable) and trying the installation again might help.\n",
    "\n",
    "Update pip:\n",
    "Ensure that your pip is up-to-date. You can upgrade pip using the following command:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!pip install --upgrade pip\n",
    "After trying these steps, you should be able to install the albumentations library without encountering the access denied error. If the issue persists, there might be deeper system configuration issues that may require additional troubleshooting.\n",
    "\n",
    "User\n",
    "---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[19], line 1\n",
    "----> 1 import albumentations as alb\n",
    "      2 augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "      3                          alb.HorizontalFlip(p=0.5), \n",
    "      4                          alb.RandomBrightnessContrast(p=0.2),\n",
    "   (...)\n",
    "      8                        bbox_params=alb.BboxParams(format='albumentations', \n",
    "      9                                                   label_fields=['class_labels']))\n",
    "\n",
    "ModuleNotFoundError: No module named 'albumentations\n",
    "\n",
    "i have installed albumentations module via !pip install --user albumentations , yet this is showing this error, how to fix this?\n",
    "ChatGPT\n",
    "The ModuleNotFoundError suggests that the Python interpreter is unable to find the albumentations module even though you've installed it. Here are a few steps to troubleshoot and resolve the issue:\n",
    "\n",
    "Check Python Version and Kernel:\n",
    "Make sure that you are using the correct Python version and kernel in your Jupyter Notebook. If you installed albumentations using a specific Python version, ensure that your Jupyter Notebook is using the same Python version. You can check the Python version by running the following code in a Jupyter cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import sys\n",
    "sys.version\n",
    "If the versions are different, you might need to install albumentations for the correct Python version or switch the Jupyter kernel.\n",
    "\n",
    "Restart the Kernel:\n",
    "After installing a new module, it's a good practice to restart the Jupyter Notebook kernel. This can be done from the Jupyter Notebook toolbar or by running the following command in a cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "%restart\n",
    "Check Installation Location:\n",
    "Verify that the installation location of albumentations matches the Python path used by Jupyter Notebook. You can check the installation location by running the following:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!pip show albumentations\n",
    "Ensure that the path displayed matches the path used by the Jupyter Notebook environment.\n",
    "\n",
    "Check sys.path in Jupyter:\n",
    "In a Jupyter cell, run the following to check the sys.path:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import sys\n",
    "sys.path\n",
    "Verify that the path where albumentations is installed is included in sys.path. If it's not, you may need to adjust your Jupyter environment or reinstall the package.\n",
    "\n",
    "Reinstall albumentations:\n",
    "Reinstall albumentations without the --user flag to ensure it is installed globally for all users:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!pip install albumentations\n",
    "After reinstalling, restart the Jupyter Notebook kernel and try importing albumentations again.\n",
    "\n",
    "Use Full Path in Notebook:\n",
    "You can try using the full path to the Python executable associated with your Jupyter environment when installing the package. Replace python with the full path to your Python executable:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!<full_path_to_python_executable> -m pip install albumentations\n",
    "After installation, restart the Jupyter kernel and try importing albumentations again.\n",
    "\n",
    "By following these steps, you should be able to resolve the ModuleNotFoundError issue and use albumentations in your Jupyter Notebook. If the problem persists, there may be some environment-specific issues that might require further investigation.\n",
    "\n",
    "User\n",
    "how to do option 6 if the folder of jupyter notebook is in C:\\\\Users\\\\whyis\\\\Desktop\\\\DevDivyansh\\\\Deep Learning\\\\DeepFaceDetection\n",
    "ChatGPT\n",
    "In option 6, you are asked to use the full path to the Python executable associated with your Jupyter environment when installing the package. Here's how you can do this:\n",
    "\n",
    "Find the Path to Your Python Executable:\n",
    "Open a command prompt or terminal and navigate to the folder where your Jupyter Notebook is located. Then, run the following command to find the path to your Python executable:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "where python\n",
    "On Windows, this might return something like:\n",
    "\n",
    "makefile\n",
    "Copy code\n",
    "C:\\Users\\whyis\\anaconda3\\python.exe\n",
    "Copy the full path to the Python executable.\n",
    "\n",
    "Install albumentations Using Full Path:\n",
    "In your Jupyter Notebook, use the full path to the Python executable to install albumentations. Replace <full_path_to_python_executable> with the actual path you copied in the previous step. Run the following command in a Jupyter cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "!C:\\Users\\whyis\\anaconda3\\python.exe -m pip install albumentations\n",
    "Make sure to adjust the path accordingly.\n",
    "\n",
    "Restart the Kernel:\n",
    "After the installation is complete, restart the Jupyter Notebook kernel. You can do this from the Jupyter Notebook toolbar or by running the %restart magic command in a cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "%restart\n",
    "Import albumentations:\n",
    "Try importing albumentations in a Jupyter cell to see if the issue is resolved:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import albumentations as alb\n",
    "This approach ensures that you are explicitly using the Python executable associated with your Jupyter environment to install the package. If the issue persists, double-check the paths, restart the kernel, and ensure that you are using the correct Python version within your Jupyter Notebook environment.\n",
    "\n",
    "User\n",
    "still saying the same error\n",
    "ChatGPT\n",
    "If you're still facing issues after trying the previous suggestions, let's try a different approach. In this case, we'll try to install albumentations directly from within the Jupyter Notebook using the %pip magic command. This command ensures that the package is installed in the context of the Jupyter environment. Here are the steps:\n",
    "\n",
    "Open a new Jupyter Notebook cell.\n",
    "\n",
    "Run the following command in the cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "%pip install albumentations\n",
    "This command is equivalent to !pip, but it explicitly uses the pip associated with the Jupyter environment.\n",
    "\n",
    "After the installation is complete, try importing albumentations:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import albumentations as alb\n",
    "If the import is successful, proceed with the rest of your code.\n",
    "\n",
    "If you encounter any errors during the installation or import, please share the error message so that I can provide more specific assistance.\n",
    "\n",
    "If this approach still doesn't work, it might be worth checking your Jupyter environment, including the Python version, kernel, and any potential conflicts with other packages. Additionally, consider restarting the Jupyter Notebook server or restarting your computer to ensure a clean environment. If the problem persists, there may be deeper issues with your Python environment that require further investigation.\n",
    "\n",
    "User\n",
    "\n",
    "#DEFINE OPTIMIZER AND LEARNING RATE\n",
    "batches_per_epoch = len(train)\n",
    "lr_decay = (1./0.75 -1)/batches_per_epoch\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[43], line 4\n",
    "      2 batches_per_epoch = len(train)\n",
    "      3 lr_decay = (1./0.75 -1)/batches_per_epoch\n",
    "----> 4 opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:110, in Adam.__init__(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\n",
    "     92 def __init__(\n",
    "     93     self,\n",
    "     94     learning_rate=0.001,\n",
    "   (...)\n",
    "    108     **kwargs\n",
    "    109 ):\n",
    "--> 110     super().__init__(\n",
    "    111         name=name,\n",
    "    112         weight_decay=weight_decay,\n",
    "    113         clipnorm=clipnorm,\n",
    "    114         clipvalue=clipvalue,\n",
    "    115         global_clipnorm=global_clipnorm,\n",
    "    116         use_ema=use_ema,\n",
    "    117         ema_momentum=ema_momentum,\n",
    "    118         ema_overwrite_frequency=ema_overwrite_frequency,\n",
    "    119         jit_compile=jit_compile,\n",
    "    120         **kwargs\n",
    "    121     )\n",
    "    122     self._learning_rate = self._build_learning_rate(learning_rate)\n",
    "    123     self.beta_1 = beta_1\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1084, in Optimizer.__init__(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\n",
    "   1082 mesh = kwargs.pop(\"mesh\", None)\n",
    "   1083 self._mesh = mesh\n",
    "-> 1084 super().__init__(\n",
    "   1085     name,\n",
    "   1086     weight_decay,\n",
    "   1087     clipnorm,\n",
    "   1088     clipvalue,\n",
    "   1089     global_clipnorm,\n",
    "   1090     use_ema,\n",
    "   1091     ema_momentum,\n",
    "   1092     ema_overwrite_frequency,\n",
    "   1093     jit_compile,\n",
    "   1094     **kwargs,\n",
    "   1095 )\n",
    "   1096 self._distribution_strategy = tf.distribute.get_strategy()\n",
    "   1097 self._run_with_dtensor = dtensor_utils.running_with_dtensor_strategy()\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:106, in _BaseOptimizer.__init__(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\n",
    "    104 self._variables = []\n",
    "    105 self._create_iteration_variable()\n",
    "--> 106 self._process_kwargs(kwargs)\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:135, in _BaseOptimizer._process_kwargs(self, kwargs)\n",
    "    133 for k in kwargs:\n",
    "    134     if k in legacy_kwargs:\n",
    "--> 135         raise ValueError(\n",
    "    136             f\"{k} is deprecated in the new Keras optimizer, please \"\n",
    "    137             \"check the docstring for valid arguments, or use the \"\n",
    "    138             \"legacy optimizer, e.g., \"\n",
    "    139             f\"tf.keras.optimizers.legacy.{self.__class__.__name__}.\"\n",
    "    140         )\n",
    "    141     else:\n",
    "    142         raise TypeError(\n",
    "    143             f\"{k} is not a valid argument, kwargs should be empty \"\n",
    "    144             \" for `optimizer_experimental.Optimizer`.\"\n",
    "    145         )\n",
    "\n",
    "ValueError: decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam.\n",
    "\n",
    "HOW TO SOLVE THIS ERROR?\n",
    "ChatGPT\n",
    "The error is indicating that the decay argument is deprecated in the new Keras optimizer, and it suggests using the legacy optimizer, such as tf.keras.optimizers.legacy.Adam.\n",
    "\n",
    "Here's how you can modify your code to use the legacy optimizer:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# DEFINE OPTIMIZER AND LEARNING RATE\n",
    "batches_per_epoch = len(train)\n",
    "lr_decay = (1.0 / 0.75 - 1) / batches_per_epoch\n",
    "\n",
    "# Use the legacy Adam optimizer\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=lr_decay)\n",
    "Replace the line where you define the optimizer with the provided code. This should resolve the ValueError related to the deprecated decay argument.\n",
    "\n",
    "However, keep in mind that using legacy components means that they might be phased out in future releases. It's a good idea to check the official documentation for the latest recommendations on how to specify the learning rate schedule or any other parameters you need. Always refer to the documentation for the specific version of TensorFlow you are using to ensure compatibility.\n",
    "\n",
    "User\n",
    "ERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\n",
    "ERROR: No matching distribution found for opencv\n",
    "how to solve this error?\n",
    "ChatGPT\n",
    "The error you're encountering suggests that there is no version of the package named \"opencv\" available on the Python Package Index (PyPI) that can be installed using the pip command. Instead, you should install the OpenCV package using the correct package name, which is usually opencv-python. Try the following command:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install opencv-python\n",
    "If you need a specific version, you can specify it like this:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install opencv-python==<desired_version>\n",
    "Remember that OpenCV is often used for computer vision tasks, and the Python package name reflects this with \"opencv-python\" being a common choice. Make sure you are using the correct package name in your installation command.\n",
    "\n",
    "User\n",
    "how to choose between a functional or a sequential API, I am going to build an ai gender and age predictor\n",
    "ChatGPT\n",
    "Choosing between the Functional API and Sequential API in Keras depends on the complexity and flexibility of your neural network architecture. Both APIs are powerful and suitable for different scenarios. Here are some considerations that might help you decide:\n",
    "\n",
    "Sequential API:\n",
    "\n",
    "Simplicity: The Sequential API is straightforward and easy to use, especially when your neural network is a linear stack of layers. If your model can be represented as a simple sequence of layers (input to output), the Sequential API is a good choice.\n",
    "Fast Prototyping: It's excellent for quick prototyping and simple models.\n",
    "Less Code: With the Sequential API, you write less code compared to the Functional API.\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_size,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "Functional API:\n",
    "\n",
    "Complex Models: If your model requires multiple inputs, shared layers, or has complex architectures such as multi-branch models, skip connections, or residual connections, the Functional API is more suitable.\n",
    "Flexibility: The Functional API provides more flexibility in connecting layers. You can easily create models with multiple inputs and outputs, and you have more control over the connections between layers.\n",
    "Feature Sharing: When you need to share layers between different parts of the model (e.g., siamese networks).\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(input_size,))\n",
    "x = Dense(64, activation='relu')(input_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "Hybrid Approach:\n",
    "\n",
    "You can also use a combination of both APIs. Start with a Sequential model and then add more complex connections using the Functional API when needed. This provides a balance between simplicity and flexibility.\n",
    "Example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "sequential_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_size,)),\n",
    "])\n",
    "\n",
    "input_layer = Input(shape=(input_size,))\n",
    "x = sequential_model(input_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "In your case of building an AI gender and age predictor, you might start with a Sequential model if the architecture is relatively simple. If you find that you need more flexibility, such as incorporating multiple inputs or shared layers, you can switch to the Functional API. Always consider the requirements of your specific model architecture and choose the API that best fits those requirements.\n",
    "\n",
    "User\n",
    "i don't want to use a pre trained model , how to build a model of my own\n",
    "ChatGPT\n",
    "Certainly! If you're building a gender and age predictor from scratch without using a pre-trained model, you would typically design a neural network architecture tailored to your specific task. Here's a basic example using TensorFlow and Keras. Note that this is just a starting point, and you may need to adjust the architecture based on your dataset and task requirements.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# Assuming you are working with image data, adjust input_size and other parameters accordingly\n",
    "input_size = (64, 64, 3)  # Assuming 64x64 RGB images\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_size))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output for dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer for gender prediction (binary classification)\n",
    "model.add(Dense(1, activation='sigmoid', name='gender_output'))\n",
    "\n",
    "# Output layer for age prediction (regression)\n",
    "model.add(Dense(1, activation='linear', name='age_output'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'gender_output': 'binary_crossentropy', 'age_output': 'mean_squared_error'},\n",
    "              metrics={'gender_output': 'accuracy', 'age_output': 'mae'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "Explanation of the components:\n",
    "\n",
    "Convolutional layers: These layers are typically used for image processing tasks.\n",
    "MaxPooling layers: Downsample the spatial dimensions to reduce computation.\n",
    "Flatten layer: Flattens the output of the convolutional layers for input to dense layers.\n",
    "Dense layers: Fully connected layers for learning high-level features.\n",
    "Dropout layer: Helps prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
    "Output layers: Separate output layers for gender prediction (binary classification) and age prediction (regression).\n",
    "Remember to adjust the architecture based on your dataset characteristics, such as image size, data type, and the specifics of your gender and age prediction task. Also, ensure that your dataset is appropriately prepared with labeled gender and age data.\n",
    "\n",
    "User\n",
    "can you give me a dataset of about 300 different people with their age and gender to train the model\n",
    "ChatGPT\n",
    "I'm sorry for any confusion, but I can't provide direct access to specific datasets as they might be subject to copyright or licensing restrictions. However, I can guide you on how to obtain suitable datasets for your gender and age prediction task.\n",
    "\n",
    "For age and gender prediction, you might want to consider using datasets such as:\n",
    "\n",
    "IMDB-WIKI Dataset:\n",
    "\n",
    "This dataset contains images from IMDb and Wikipedia along with labels for age and gender.\n",
    "You can find the dataset here: https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
    "UTKFace Dataset:\n",
    "\n",
    "This dataset includes facial images with age and gender labels.\n",
    "Dataset link: https://susanqq.github.io/UTKFace/\n",
    "Adience Benchmark:\n",
    "\n",
    "The Adience dataset is designed for age and gender classification.\n",
    "Dataset link: https://talhassner.github.io/home/projects/Adience/Adience-data.html\n",
    "UTZappos50K Dataset:\n",
    "\n",
    "Although primarily a footwear dataset, it includes images of faces with age and gender labels.\n",
    "Dataset link: http://vision.cs.utexas.edu/projects/finegrained/utzap50k/\n",
    "Before using any dataset, ensure that you review and comply with the terms of use, licensing agreements, and any other relevant guidelines provided by the dataset creators.\n",
    "\n",
    "To load and preprocess image datasets, you can use libraries such as TensorFlow (tf.keras.preprocessing.image) or OpenCV. For tabular data, you can use Pandas to handle the data.\n",
    "\n",
    "Here's a simplified example using Pandas to create a synthetic dataset for illustration:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a synthetic dataset with age and gender labels\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random age and gender data for 300 people\n",
    "ages = np.random.randint(18, 70, size=300)\n",
    "genders = np.random.choice(['Male', 'Female'], size=300)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Age': ages, 'Gender': genders})\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "df.to_csv('synthetic_dataset.csv', index=False)\n",
    "In a real-world scenario, you would replace the synthetic dataset with the actual data from the dataset you choose. Make sure to follow the dataset's documentation and preprocessing guidelines for the specific task you are working on.\n",
    "\n",
    "User\n",
    "i have 13,529 image dataset containing images of people of various age, sex and race encoded within the filename as : [age]_[sex]_[race]_[time&dateOfImageCollection].jpg ; age is between 0 and 116, for sex 0-male and 1-female ; race 0-white,1-black,2-asian,3-indian and 4-others; now I want to build a dataset with proper labels in the jupyter notebook\n",
    "ChatGPT\n",
    "To build a dataset with proper labels in a Jupyter Notebook from the filenames you provided, you'll need to extract the age, sex, and race information from each filename and create corresponding labels. You can use the os and Pandas libraries for file and data manipulation. Here's a step-by-step guide:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing your image files\n",
    "image_dir = 'path/to/your/images'\n",
    "\n",
    "# List to store data\n",
    "data = []\n",
    "\n",
    "# Iterate through the image files\n",
    "for filename in os.listdir(image_dir):\n",
    "    # Extract information from the filename\n",
    "    age, sex, race, _ = filename.split('_')\n",
    "    \n",
    "    # Convert strings to appropriate data types\n",
    "    age = int(age)\n",
    "    sex = int(sex)\n",
    "    race = int(race)\n",
    "    \n",
    "    # Append the data as a tuple\n",
    "    data.append((filename, age, sex, race))\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "df = pd.DataFrame(data, columns=['Filename', 'Age', 'Sex', 'Race'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "Now, you have a Pandas DataFrame (df) that contains the filename, age, sex, and race information. You can further process this DataFrame to encode labels for age, sex, and race, if necessary.\n",
    "\n",
    "Here's how you can encode labels:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Encode labels for age, sex, and race\n",
    "# You may need to adjust the encoding strategy based on your specific task\n",
    "\n",
    "# Encoding age into age groups (e.g., 0-10, 11-20, ..., 111-120)\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]\n",
    "age_labels = [f'{i}-{i+9}' for i in range(0, 120, 10)]\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# One-hot encode sex and race\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Race'], prefix=['Sex', 'Race'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()\n",
    "Now, the DataFrame (df) includes one-hot encoded columns for sex and race, and the 'Age' column is replaced with 'AgeGroup'. You can use this DataFrame as the basis for constructing your training dataset.\n",
    "\n",
    "If you need to save this DataFrame to a CSV file for later use, you can use the following:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df.to_csv('your_dataset.csv', index=False)\n",
    "Replace 'path/to/your/images' with the actual path to your image directory. Adjust the encoding strategies based on your specific needs and task requirements.\n",
    "\n",
    "User\n",
    "can we use tf.keras.utils.image_dataset_from_directory?\n",
    "ChatGPT\n",
    "Yes, you can use tf.keras.utils.image_dataset_from_directory to create a dataset from image files organized in directories. However, the structure of your image directory needs to be organized in a way that the function can automatically infer labels from subdirectories. In your case, with filenames containing age, sex, and race information, you may need to preprocess the data and organize it in a specific structure.\n",
    "\n",
    "Assuming your dataset directory has a structure like:\n",
    "\n",
    "lua\n",
    "Copy code\n",
    "dataset/\n",
    "|-- 0_0_0_20220101.jpg\n",
    "|-- 1_1_1_20220102.jpg\n",
    "|-- ...\n",
    "|-- subdirectory1/\n",
    "|   |-- image1.jpg\n",
    "|   |-- image2.jpg\n",
    "|   |-- ...\n",
    "|-- subdirectory2/\n",
    "|   |-- image3.jpg\n",
    "|   |-- image4.jpg\n",
    "|   |-- ...\n",
    "|-- ...\n",
    "You can use tf.keras.utils.image_dataset_from_directory as follows:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to your dataset directory\n",
    "dataset_dir = 'path/to/your/dataset'\n",
    "\n",
    "# Define image size and batch size\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Create the image dataset\n",
    "image_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Display class names (age, sex, race)\n",
    "class_names = image_dataset.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Visualize a few images from the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in image_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()\n",
    "Make sure to replace 'path/to/your/dataset' with the actual path to your dataset directory. Adjust image_size and batch_size as needed.\n",
    "\n",
    "Note: tf.keras.utils.image_dataset_from_directory expects subdirectories in your dataset directory to represent classes (labels). It assumes that the images in each subdirectory belong to the corresponding class. If your images are not organized in this way, you might need to preprocess your data to create subdirectories based on your labels or use a custom data loading approach.\n",
    "\n",
    "User\n",
    "how can i augment on this data using albumentations\n",
    "ChatGPT\n",
    "To augment your image dataset using Albumentations, you can create a custom data generator that applies the augmentation transformations to the images. Here's an example of how you can integrate Albumentations with TensorFlow's tf.data.Dataset:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "from albumentations.tf_compat import AlbumentationsWrapper\n",
    "\n",
    "# Path to your dataset directory\n",
    "dataset_dir = 'path/to/your/dataset'\n",
    "\n",
    "# Define image size and batch size\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Define the augmentation pipeline using Albumentations\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Add more transformations as needed\n",
    "])\n",
    "\n",
    "# Define a function to apply augmentation to a single image\n",
    "def augment_image(image):\n",
    "    data = {\"image\": image}\n",
    "    augmented = augmentation_pipeline(**data)\n",
    "    return augmented[\"image\"]\n",
    "\n",
    "# Create the image dataset\n",
    "image_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Apply augmentation to the images using map function\n",
    "augmented_dataset = image_dataset.map(lambda x, y: (tf.py_function(augment_image, [x], [tf.uint8])[0], y))\n",
    "\n",
    "# Visualize a few original and augmented images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for original_images, _ in image_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(original_images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for augmented_images, _ in augmented_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"Augmented\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "In this example:\n",
    "\n",
    "augmentation_pipeline defines the transformations you want to apply using Albumentations.\n",
    "augment_image is a function that applies the Albumentations transformations to a single image using tf.py_function.\n",
    "map is used to apply the augmentation to the entire dataset.\n",
    "This is a basic example, and you can customize the augmentation pipeline according to your requirements. Adjust the transformations in augmentation_pipeline based on the type of augmentations you want to perform.\n",
    "\n",
    "Make sure to install the required libraries:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install albumentations tensorflow matplotlib\n",
    "Note: Applying augmentations during training is common, but be cautious about applying the same augmentations to the validation dataset, as you want the validation set to represent the original data distribution. You can create a separate dataset for validation without augmentation.\n",
    "\n",
    "User\n",
    "how can i augment on this dataset of pandas using albumentations\n",
    "ChatGPT\n",
    "To augment a dataset of images stored in a Pandas DataFrame using Albumentations, you can follow these steps:\n",
    "\n",
    "Install the required libraries:\n",
    "bash\n",
    "Copy code\n",
    "pip install albumentations pandas\n",
    "Load your dataset into a Pandas DataFrame. I'll assume your DataFrame has a column named 'Image_Path' containing the file paths of your images.\n",
    "\n",
    "Define the augmentation pipeline using Albumentations.\n",
    "\n",
    "Write a function to apply the augmentation to each image and save the augmented images.\n",
    "\n",
    "Here's an example code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "# Load your dataset into a Pandas DataFrame\n",
    "# Assuming 'Image_Path' is the column with file paths\n",
    "df = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Path to the directory where augmented images will be saved\n",
    "output_dir = 'path/to/augmented_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the augmentation pipeline using Albumentations\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Add more transformations as needed\n",
    "])\n",
    "\n",
    "# Define a function to apply augmentation to each image\n",
    "def augment_and_save(image_path, output_dir):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented = augmentation_pipeline(image=image)\n",
    "    augmented_image = augmented['image']\n",
    "\n",
    "    # Extract file name and extension\n",
    "    file_name = os.path.basename(image_path)\n",
    "    base_name, extension = os.path.splitext(file_name)\n",
    "\n",
    "    # Save the augmented image\n",
    "    output_path = os.path.join(output_dir, f'{base_name}_augmented{extension}')\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Apply augmentation to each image in the dataset\n",
    "for index, row in df.iterrows():\n",
    "    image_path = row['Image_Path']\n",
    "    augment_and_save(image_path, output_dir)\n",
    "In this example:\n",
    "\n",
    "augmentation_pipeline defines the transformations you want to apply using Albumentations.\n",
    "augment_and_save is a function that reads an image, applies the Albumentations transformations, and saves the augmented image.\n",
    "Make sure to replace 'path/to/your/dataset.csv' with the actual path to your dataset CSV file and adjust the column names accordingly. Also, specify the output directory where augmented images will be saved in output_dir.\n",
    "\n",
    "User\n",
    "a funny hindi poem line to describe a short period of happyness\n",
    "ChatGPT\n",
    "\"  ,     ,\n",
    "  ,    \"\n",
    "\n",
    "User\n",
    "how to split the above data into train(70%) val (15%) and test(15%) ?\n",
    "ChatGPT\n",
    "You can use the train_test_split function from the scikit-learn library to split your data into training, validation, and test sets. Here's an example of how you can do it:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your Pandas DataFrame\n",
    "# 'Image_Path' is the column with file paths, and 'Label' is the column with labels\n",
    "\n",
    "# Split into training (70%) and temp (30%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split temp_df into validation (50%) and test (50%)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the sizes of the datasets\n",
    "print(f\"Train set size: {len(train_df)} samples\")\n",
    "print(f\"Validation set size: {len(val_df)} samples\")\n",
    "print(f\"Test set size: {len(test_df)} samples\")\n",
    "In this example:\n",
    "\n",
    "train_test_split is used twice to create the training set and a temporary set (temp_df).\n",
    "The second call to train_test_split is used to split the temporary set into validation and test sets.\n",
    "Make sure to adjust the column names ('Image_Path', 'Label') based on your actual DataFrame structure.\n",
    "\n",
    "This code snippet assumes you have a column named 'Label' (or something similar) containing the labels for your data. Adjust the splitting ratio and random state according to your preferences.\n",
    "\n",
    "User\n",
    "how to change the name of a file in jupyter\n",
    "ChatGPT\n",
    "To change the name of a file in Jupyter Notebook, you can use the following steps:\n",
    "\n",
    "Navigate to the directory where the file is located:\n",
    "You can use the %cd magic command to change the current working directory if needed.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "%cd path/to/directory\n",
    "Use the os.rename function:\n",
    "You can use the os.rename function to change the name of a file. Provide the current filename and the new filename as arguments.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import os\n",
    "\n",
    "current_filename = 'old_filename.txt'\n",
    "new_filename = 'new_filename.txt'\n",
    "\n",
    "os.rename(current_filename, new_filename)\n",
    "Replace 'old_filename.txt' with the current name of the file you want to rename and 'new_filename.txt' with the desired new name.\n",
    "\n",
    "Here's an example that combines these steps in a Jupyter Notebook cell:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import os\n",
    "\n",
    "# Navigate to the directory (change to your actual path)\n",
    "%cd path/to/directory\n",
    "\n",
    "# Specify the current and new filenames\n",
    "current_filename = 'old_filename.txt'\n",
    "new_filename = 'new_filename.txt'\n",
    "\n",
    "# Rename the file\n",
    "os.rename(current_filename, new_filename)\n",
    "Remember to replace 'path/to/directory', 'old_filename.txt', and 'new_filename.txt' with the appropriate values for your use case.\n",
    "\n",
    "After running the cell, the file will be renamed in the specified directory. Note that this operation is irreversible, so make sure you want to permanently change the filename.\n",
    "\n",
    "User\n",
    "how to scale this data i.e deviding the pixels by 255\n",
    "ChatGPT\n",
    "If you want to scale the pixel values of an image in your dataset by dividing them by 255, you can apply this transformation to each image. Assuming you are using a Pandas DataFrame and the 'Image_Path' column contains the file paths of your images, you can modify the previous code to include this scaling operation. Here's an example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# Load your dataset into a Pandas DataFrame\n",
    "# Assuming 'Image_Path' is the column with file paths\n",
    "df = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Scale the pixel values by dividing them by 255\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image / 255.0  # Scale pixel values\n",
    "    return image\n",
    "\n",
    "df['Image'] = df['Image_Path'].apply(preprocess_image)\n",
    "\n",
    "# Split the dataset\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define the augmentation pipeline using Albumentations\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Define a function to apply augmentation to each image\n",
    "def augment_and_preprocess(image, label):\n",
    "    augmented = augmentation_pipeline(image=image)\n",
    "    augmented_image = augmented['image']\n",
    "    return augmented_image, label\n",
    "\n",
    "# Apply augmentation and preprocessing to each image in the dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df['Image'].values, train_df['Label'].values))\n",
    "train_dataset = (\n",
    "    train_dataset\n",
    "    .map(lambda image, label: augment_and_preprocess(image, label), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Repeat the process for the validation and test datasets\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_df['Image'].values, val_df['Label'].values))\n",
    "val_dataset = (\n",
    "    val_dataset\n",
    "    .map(lambda image, label: augment_and_preprocess(image, label), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_df['Image'].values, test_df['Label'].values))\n",
    "test_dataset = (\n",
    "    test_dataset\n",
    "    .map(lambda image, label: augment_and_preprocess(image, label), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "In this example, the preprocess_image function is applied to each image in the dataset, scaling the pixel values by dividing them by 255. The augmented images are also scaled as part of the preprocessing steps. The ToTensorV2() transformation from Albumentations is used to convert the images to PyTorch tensors. Adjust the code according to your specific needs and the deep learning framework you are using.\n",
    "\n",
    "User\n",
    "now that i have split the data into train test and split, how to use mobileNet to make a neural network that can take input of the images and give prediction of their age, sex and race'\n",
    "ChatGPT\n",
    "To use MobileNet for a multi-output neural network that predicts age, sex, and race from images, you can create a model using TensorFlow and Keras. First, ensure you have the necessary libraries installed:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install tensorflow\n",
    "Now, you can create a model using MobileNet as the base and add dense layers for each output. I'll provide you with a simple example using the functional API of Keras. Note that this is a basic example, and you might need to adjust the architecture based on your specific requirements.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input shape (adjust based on your images)\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Load MobileNet model with pre-trained weights (include_top=False removes the final dense layer)\n",
    "base_model = MobileNet(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define additional layers for each output (age, sex, race)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "In this example:\n",
    "\n",
    "The MobileNet base model is loaded with pre-trained weights, and its layers are frozen.\n",
    "Additional dense layers are added for each output (age, sex, race).\n",
    "The model is compiled with appropriate loss functions and metrics for each output.\n",
    "Ensure that your data is prepared with the correct labels for age, sex, and race. Also, customize the architecture based on your specific requirements and the size of your dataset.\n",
    "\n",
    "For training, you can use the fit method on your model with the training dataset (train_dataset), validation dataset (val_dataset), and appropriate number of epochs.\n",
    "\n",
    "User\n",
    "i want to do it using a mobileNet v2 architecture\n",
    "ChatGPT\n",
    "Sure, you can use MobileNetV2 as the base model in a similar manner. Here's an example of how you can create a multi-output neural network with MobileNetV2 using TensorFlow and Keras:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers for each output\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "Make sure you have the necessary libraries installed:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install tensorflow\n",
    "In this example, MobileNetV2 is used as the base model, and additional dense layers are added for each output (age, sex, race). The model is then compiled with appropriate loss functions and metrics for each output.\n",
    "\n",
    "You can customize the architecture, adjust hyperparameters, and train the model using the appropriate datasets and epochs based on your specific requirements.\n",
    "\n",
    "User\n",
    "the predicted output should be  age is between 0 and 116, for sex: 0-male and 1-female ; race 0-white,1-black,2-asian,3-indian and 4-others; the actual values are stored in a csv file\n",
    "ChatGPT\n",
    "If you have a CSV file with the actual values for age, sex, and race, you can use that file to load the data and train your model. Ensure that your CSV file has columns named 'age', 'sex', and 'race' representing the target labels for each sample.\n",
    "\n",
    "Here's an example of how you can load the data and train the model:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load your dataset from the CSV file\n",
    "csv_path = 'path/to/your/dataset.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers for each output\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Assuming you have image paths in the 'Image_Path' column\n",
    "image_paths = df['Image_Path'].values\n",
    "\n",
    "# Assuming you have labels in 'age', 'sex', and 'race' columns\n",
    "age_labels = df['age'].values\n",
    "sex_labels = df['sex'].values\n",
    "race_labels = df['race'].values\n",
    "\n",
    "# Assuming you have one-hot encoded race labels\n",
    "race_labels_onehot = tf.keras.utils.to_categorical(race_labels, num_classes=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    # Assuming you have a function to load and preprocess images\n",
    "    image_data_generator(image_paths, batch_size=32),\n",
    "    {'age_output': age_labels, 'sex_output': sex_labels, 'race_output': race_labels_onehot},\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")\n",
    "Replace 'path/to/your/dataset.csv' with the actual path to your CSV file. Make sure your CSV file has columns like 'Image_Path', 'age', 'sex', and 'race' as mentioned.\n",
    "\n",
    "Adjust the data loading and preprocessing steps based on your actual dataset and file structure. The training loop assumes you have a function image_data_generator that loads and preprocesses images. You may need to customize it based on your data loading pipeline.\n",
    "\n",
    "User\n",
    "how to resize the images to 224,224,3?\n",
    "ChatGPT\n",
    "To resize images to 224x224 pixels with 3 channels (assuming RGB), you can use a library like OpenCV in Python. Here's an example of how you can resize images using OpenCV:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to the directory containing your images\n",
    "images_dir = 'path/to/your/images'\n",
    "\n",
    "# Create a new directory to save resized images\n",
    "resized_images_dir = 'path/to/your/resized_images'\n",
    "os.makedirs(resized_images_dir, exist_ok=True)\n",
    "\n",
    "# Read the CSV file containing image paths\n",
    "df = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Resize and save images\n",
    "for index, row in df.iterrows():\n",
    "    image_path = os.path.join(images_dir, row['Image_Path'])\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to 224x224\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Save the resized image to the new directory\n",
    "    new_image_path = os.path.join(resized_images_dir, row['Image_Path'])\n",
    "    cv2.imwrite(new_image_path, img_resized)\n",
    "\n",
    "# Update the 'Image_Path' column in the DataFrame with the new paths\n",
    "df['Image_Path'] = df['Image_Path'].apply(lambda x: os.path.join(resized_images_dir, x))\n",
    "\n",
    "# Save the updated DataFrame with resized image paths\n",
    "df.to_csv('path/to/your/updated_dataset.csv', index=False)\n",
    "This code assumes that your original images are stored in images_dir, and it creates a new directory resized_images_dir to store the resized images. The code iterates through the DataFrame, reads each image, resizes it to 224x224 pixels, and saves it in the new directory. Finally, it updates the 'Image_Path' column in the DataFrame with the paths to the resized images and saves the updated DataFrame.\n",
    "\n",
    "Make sure to replace 'path/to/your/dataset.csv', 'path/to/your/images', and 'path/to/your/resized_images' with the actual paths in your project.\n",
    "\n",
    "User\n",
    "error                                     Traceback (most recent call last)\n",
    "Cell In[10], line 23\n",
    "     20 img = cv2.imread(image_path)\n",
    "     22 # Resize the image to 224x224\n",
    "---> 23 img_resized = cv2.resize(img, (224, 224))\n",
    "     25 # Save the resized image to the new directory\n",
    "     26 new_image_path = os.path.join(resized_images_dir, row['Filename'])\n",
    "\n",
    "error: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
    "\n",
    "this error comes on executing the above code\n",
    "ChatGPT\n",
    "The error you're encountering ((-215:Assertion failed) !ssize.empty() in function 'cv::resize') indicates that OpenCV is unable to resize the image because the image is not being read correctly. This can happen if the image file path is incorrect or if the image file is not present at the specified location.\n",
    "\n",
    "Here are a few things to check and modify in your code:\n",
    "\n",
    "Verify that the paths to your images are correctly specified in the 'Image_Path' column of your DataFrame.\n",
    "\n",
    "Ensure that the images are present at the specified paths. Double-check the directory structure and file names.\n",
    "\n",
    "Here's a modified version of the code with a few changes:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing your images\n",
    "images_dir = 'path/to/your/images'\n",
    "\n",
    "# Create a new directory to save resized images\n",
    "resized_images_dir = 'path/to/your/resized_images'\n",
    "os.makedirs(resized_images_dir, exist_ok=True)\n",
    "\n",
    "# Read the CSV file containing image paths\n",
    "df = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Resize and save images\n",
    "for index, row in df.iterrows():\n",
    "    image_path = os.path.join(images_dir, row['Image_Path'])\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if os.path.isfile(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the image to 224x224\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        \n",
    "        # Save the resized image to the new directory\n",
    "        new_image_path = os.path.join(resized_images_dir, row['Image_Path'])\n",
    "        cv2.imwrite(new_image_path, img_resized)\n",
    "    else:\n",
    "        print(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "# Update the 'Image_Path' column in the DataFrame with the new paths\n",
    "df['Image_Path'] = df['Image_Path'].apply(lambda x: os.path.join(resized_images_dir, x))\n",
    "\n",
    "# Save the updated DataFrame with resized image paths\n",
    "df.to_csv('path/to/your/updated_dataset.csv', index=False)\n",
    "This modified code includes a check (os.path.isfile(image_path)) to verify if the image file exists before attempting to read and resize it. If the file doesn't exist, a message will be printed indicating that the image was not found at the specified path. Make sure to adjust the paths and filenames based on your project structure.\n",
    "\n",
    "User\n",
    "error                                     Traceback (most recent call last)\n",
    "Cell In[11], line 27\n",
    "     25     # Save the resized image to the new directory\n",
    "     26     new_image_path = os.path.join(resized_images_dir, row['Filename'])\n",
    "---> 27     cv2.imwrite(new_image_path, img_resized)\n",
    "     29 # Update the 'Image_Path' column in the DataFrame with the new paths\n",
    "     30 df['Filename'] = df['Filename'].apply(lambda x: os.path.join(resized_images_dir, x))\n",
    "\n",
    "error: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:696: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'cv::imwrite_'\n",
    "\n",
    "now this is coming\n",
    "ChatGPT\n",
    "The error indicates that OpenCV could not find a writer for the specified image extension when attempting to save the resized image using cv2.imwrite. This typically happens when the file extension in new_image_path is not recognized by OpenCV.\n",
    "\n",
    "Ensure that the 'Filename' column in your DataFrame contains valid file names with recognized image extensions (e.g., '.jpg', '.png', etc.). If you're using a custom file extension or there's a mistake in the file names, OpenCV may not be able to determine the appropriate writer.\n",
    "\n",
    "Here's a modified version of the code to correct the issue:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the directory containing your images\n",
    "images_dir = 'path/to/your/images'\n",
    "\n",
    "# Create a new directory to save resized images\n",
    "resized_images_dir = 'path/to/your/resized_images'\n",
    "os.makedirs(resized_images_dir, exist_ok=True)\n",
    "\n",
    "# Read the CSV file containing image paths\n",
    "df = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Resize and save images\n",
    "for index, row in df.iterrows():\n",
    "    image_path = os.path.join(images_dir, row['Image_Path'])\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if os.path.isfile(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the image to 224x224\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        \n",
    "        # Extract the file extension from the original image path\n",
    "        _, file_extension = os.path.splitext(row['Image_Path'])\n",
    "        \n",
    "        # Save the resized image to the new directory with the correct extension\n",
    "        new_image_path = os.path.join(resized_images_dir, row['Image_Path'])\n",
    "        cv2.imwrite(new_image_path, img_resized)\n",
    "    else:\n",
    "        print(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "# Update the 'Image_Path' column in the DataFrame with the new paths\n",
    "df['Image_Path'] = df['Image_Path'].apply(lambda x: os.path.join(resized_images_dir, x))\n",
    "\n",
    "# Save the updated DataFrame with resized image paths\n",
    "df.to_csv('path/to/your/updated_dataset.csv', index=False)\n",
    "This code extracts the file extension from the original image path and uses it when saving the resized image to ensure that OpenCV recognizes the correct writer for the specified extension. Adjust the paths and filenames accordingly based on your project structure.\n",
    "\n",
    "User\n",
    "error                                     Traceback (most recent call last)\n",
    "Cell In[14], line 12\n",
    "     10 for index, row in df.iterrows():\n",
    "     11     image_path = os.path.join(data_dir,row['Filename'])\n",
    "---> 12     preprocess_image(image_path)\n",
    "     14 # Split the dataset\n",
    "     15 train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "Cell In[14], line 7, in preprocess_image(image_path)\n",
    "      5 def preprocess_image(image_path):\n",
    "      6     image = cv2.imread(image_path)\n",
    "----> 7     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      8     image = image / 255.0  # Scale pixel values\n",
    "      9     return image\n",
    "\n",
    "error: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
    "ChatGPT\n",
    "The error you're encountering ((-215:Assertion failed) !_src.empty() in function 'cv::cvtColor') indicates that the image could not be read correctly, resulting in an empty image (_src.empty()).\n",
    "\n",
    "Here are some things to check and address:\n",
    "\n",
    "Image Path Correctness: Ensure that the paths in your DataFrame ('Filename' column) are correct and point to valid image files.\n",
    "\n",
    "Image File Existence: Make sure that the images exist at the specified paths. Check if the images are present in the specified directory.\n",
    "\n",
    "File Extension: Ensure that the file extension in the DataFrame corresponds to the actual image file format (e.g., '.jpg', '.png', etc.).\n",
    "\n",
    "Here's a modified version of your code with additional error handling:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your DataFrame has a column named 'Filename' with image file paths\n",
    "data_dir = 'path/to/your/dataset'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'your_dataset.csv'))\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = image / 255.0  # Scale pixel values\n",
    "            return image\n",
    "        else:\n",
    "            print(f\"Error: Unable to read image at path {image_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the preprocess_image function to each row in the DataFrame\n",
    "df['Image'] = df['Filename'].apply(lambda x: preprocess_image(os.path.join(data_dir, x)))\n",
    "\n",
    "# Filter out rows with None (failed to load image)\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the dataset\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Continue with your code...\n",
    "This modification includes error handling in the preprocess_image function. If an image cannot be read or converted correctly, it prints an error message and returns None. Rows with None are then dropped from the DataFrame. This should help you identify which images are causing the problem. Adjust the paths and file names as needed.\n",
    "\n",
    "User\n",
    "#Making a full dataset consisting of both original and augmented data\n",
    "for filename in os.listdir('data'):\n",
    "    try:\n",
    "        os.path.join('full_data',filename)\n",
    "    except:\n",
    "        print(\"Issue with image \",filename)\n",
    "        os.remove(os.path.join('data',filename))\n",
    "        \n",
    "for filename in os.listdir('augmented_data'):\n",
    "    try:\n",
    "        os.path.join('full_data',filename)\n",
    "    except:\n",
    "        print(\"Issue with image \",filename)\n",
    "        os.remove(os.path.join('augmented_data',filename))\n",
    "why is this not able to copy data from two folders 'data' and 'augmented_data\" to \"full_data\"? \n",
    "ChatGPT\n",
    "Your code is using os.path.join('full_data', filename), but you're not assigning the result of os.path.join to anything or actually copying or moving the files. The os.path.join function just creates a path by joining folder names and filenames but doesn't perform any file operations.\n",
    "\n",
    "If you want to copy files from both the 'data' and 'augmented_data' folders to the 'full_data' folder, you should use the shutil.copy or shutil.copyfile function for each file. Here's an updated version of your code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create 'full_data' directory if it doesn't exist\n",
    "os.makedirs('full_data', exist_ok=True)\n",
    "\n",
    "# Copy files from 'data' to 'full_data'\n",
    "for filename in os.listdir('data'):\n",
    "    try:\n",
    "        source_path = os.path.join('data', filename)\n",
    "        destination_path = os.path.join('full_data', filename)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with image {filename}: {e}\")\n",
    "        os.remove(source_path)\n",
    "\n",
    "# Copy files from 'augmented_data' to 'full_data'\n",
    "for filename in os.listdir('augmented_data'):\n",
    "    try:\n",
    "        source_path = os.path.join('augmented_data', filename)\n",
    "        destination_path = os.path.join('full_data', filename)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with image {filename}: {e}\")\n",
    "        os.remove(source_path)\n",
    "This code uses shutil.copy to copy files from the source folders ('data' and 'augmented_data') to the 'full_data' folder. If an issue occurs during the copying process, it prints an error message and attempts to remove the problematic file.\n",
    "\n",
    "Make sure to adapt the code according to your specific requirements and handle errors in a way that suits your use case.\n",
    "\n",
    "User\n",
    "#Making a full dataset consisting of both original and augmented data\n",
    "for filename in os.listdir('data'):\n",
    "    image_path=os.path.join('data',filename)\n",
    "    try:\n",
    "        cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        output_path = os.path.join('full_data',filename)\n",
    "        cv2.imwrite(output_path,image)\n",
    "    except Exception as e:\n",
    "        print(\"Issue with image \",filename,\" \",e)\n",
    "        \n",
    "for filename in os.listdir('augmented_data'):\n",
    "    image_path=os.path.join('augmented_data',filename)\n",
    "    try:\n",
    "        cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        output_path = os.path.join('full_data',filename)\n",
    "        cv2.imwrite(output_path,image)\n",
    "    except Exception as e:\n",
    "        print(\"Issue with image \",filename,\" \",e)\n",
    "is this code okay to copy files from \"data\" and \"augmented_data\" folders to \"full_data\" , I don't want any error\n",
    "ChatGPT\n",
    "There are a couple of issues in your code that need to be addressed. Let me provide you with a corrected version:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Create 'full_data' directory if it doesn't exist\n",
    "os.makedirs('full_data', exist_ok=True)\n",
    "\n",
    "# Copy files from 'data' to 'full_data'\n",
    "for filename in os.listdir('data'):\n",
    "    try:\n",
    "        image_path = os.path.join('data', filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            output_path = os.path.join('full_data', filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with image {filename}: {e}\")\n",
    "\n",
    "# Copy files from 'augmented_data' to 'full_data'\n",
    "for filename in os.listdir('augmented_data'):\n",
    "    try:\n",
    "        image_path = os.path.join('augmented_data', filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            output_path = os.path.join('full_data', filename)\n",
    "            cv2.imwrite(output_path, image)\n",
    "    except Exception as e:\n",
    "        print(f\"Issue with image {filename}: {e}\")\n",
    "Changes made:\n",
    "\n",
    "Moved the os.makedirs outside the loop to create the 'full_data' directory only once.\n",
    "Checked if cv2.imread returns a valid image before proceeding to convert and save it.\n",
    "Corrected the variable names (image_path, image, and output_path) to avoid any confusion.\n",
    "This corrected code should help prevent errors and ensure that images are copied successfully from 'data' and 'augmented_data' folders to the 'full_data' folder.\n",
    "\n",
    "User\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "#neural network\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "ChatGPT\n",
    "It seems like your code got cut off. If you have any specific questions or if you need assistance with a particular part of your code, please provide more details, and I'll be happy to help!\n",
    "\n",
    "User\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "#neural network\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)\n",
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers for each output\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "this is my neural network, how to train it?\n",
    "ChatGPT\n",
    "To train your neural network, you can use the fit method provided by the Keras API in TensorFlow. Here's an example of how you can train your model:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Assuming you have the necessary data loaded into NumPy arrays or TensorFlow datasets\n",
    "# Modify the data loading part based on your actual data format\n",
    "\n",
    "# Example data loading\n",
    "train_images, (train_age_labels, train_sex_labels, train_race_labels) = load_train_data(train_df)\n",
    "val_images, (val_age_labels, val_sex_labels, val_race_labels) = load_val_data(val_df)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels},\n",
    "    validation_data=(val_images, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "In this example:\n",
    "\n",
    "train_images, val_images are the input images.\n",
    "train_age_labels, val_age_labels, train_sex_labels, val_sex_labels, train_race_labels, val_race_labels are the corresponding labels for age, sex, and race.\n",
    "Make sure to replace load_train_data and load_val_data with your actual data loading functions. The data loading functions should return NumPy arrays or TensorFlow datasets containing the images and their corresponding labels.\n",
    "\n",
    "Adjust the batch size, number of epochs, and other hyperparameters based on your specific requirements. The fit method automatically handles training the model and validating on the validation set.\n",
    "\n",
    "After training, you can use the trained model for predictions on new data. If you have a test set (test_df), you can evaluate the model on it using the evaluate method:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "test_images, (test_age_labels, test_sex_labels, test_race_labels) = load_test_data(test_df)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(\n",
    "    test_images,\n",
    "    {'age_output': test_age_labels, 'sex_output': test_sex_labels, 'race_output': test_race_labels}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Age MAE:\", eval_result[1])\n",
    "print(\"Test Sex Accuracy:\", eval_result[2])\n",
    "print(\"Test Race Accuracy:\", eval_result[3])\n",
    "Make sure to adjust the data loading for the test set accordingly.\n",
    "\n",
    "Remember to preprocess your data appropriately (e.g., normalization, augmentation) before feeding it into the neural network.\n",
    "\n",
    "User\n",
    "the actual data is stored in a csv file 'resized_full_dataset.csv'\n",
    "ChatGPT\n",
    "To train your model using the data from the 'resized_full_dataset.csv' file, you'll need to perform the following steps:\n",
    "\n",
    "Load and preprocess the data:\n",
    "\n",
    "Load the CSV file using a library like Pandas.\n",
    "Preprocess the data, including loading and resizing images.\n",
    "Split the data into training, validation, and test sets:\n",
    "\n",
    "Split the data into training, validation, and test sets using train_test_split or any other method.\n",
    "Define and compile the model:\n",
    "\n",
    "Define your neural network model with the specified architecture for age, sex, and race predictions.\n",
    "Compile the model with the appropriate loss functions and metrics.\n",
    "Train the model:\n",
    "\n",
    "Train the model using the training set and validate on the validation set.\n",
    "Evaluate the model:\n",
    "\n",
    "Evaluate the trained model on the test set to assess its performance.\n",
    "Here's an example code snippet to guide you through the process:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "df = pd.read_csv('resized_full_dataset.csv')\n",
    "\n",
    "# Your data loading and preprocessing logic here...\n",
    "# For example, if 'Image_Path' contains file paths, load and preprocess the images\n",
    "\n",
    "# Step 2: Split the data\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 3: Define and compile the model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Step 4: Train the model\n",
    "# Your data loading and preprocessing logic here...\n",
    "# For example, if 'Image_Path' contains file paths, load and preprocess the images\n",
    "train_images = ...  # Your code to load and preprocess training images\n",
    "val_images = ...    # Your code to load and preprocess validation images\n",
    "\n",
    "train_age_labels = train_df['Age'].values\n",
    "train_sex_labels = train_df['Sex'].values\n",
    "train_race_labels = train_df['Race'].values\n",
    "\n",
    "val_age_labels = val_df['Age'].values\n",
    "val_sex_labels = val_df['Sex'].values\n",
    "val_race_labels = val_df['Race'].values\n",
    "\n",
    "# Convert race labels to categorical\n",
    "label_encoder = LabelEncoder()\n",
    "train_race_labels_encoded = label_encoder.fit_transform(train_race_labels)\n",
    "val_race_labels_encoded = label_encoder.transform(val_race_labels)\n",
    "\n",
    "train_race_labels_one_hot = to_categorical(train_race_labels_encoded, num_classes=5)\n",
    "val_race_labels_one_hot = to_categorical(val_race_labels_encoded, num_classes=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(val_images, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_images = ...  # Your code to load and preprocess test images\n",
    "test_age_labels = test_df['Age'].values\n",
    "test_sex_labels = test_df['Sex'].values\n",
    "test_race_labels = test_df['Race'].values\n",
    "\n",
    "# Convert race labels to categorical\n",
    "test_race_labels_encoded = label_encoder.transform(test_race_labels)\n",
    "test_race_labels_one_hot = to_categorical(test_race_labels_encoded, num_classes=5)\n",
    "\n",
    "eval_result = model.evaluate(\n",
    "    test_images,\n",
    "    {'age_output': test_age_labels, 'sex_output': test_sex_labels, 'race_output': test_race_labels_one_hot}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Age MAE:\", eval_result[1])\n",
    "print(\"Test Sex Accuracy:\", eval_result[2])\n",
    "print(\"Test Race Accuracy:\", eval_result[3])\n",
    "This code provides a general structure for loading and preprocessing data, defining the model architecture, training the model, and evaluating its performance. You may need to adapt it based on the actual structure of your dataset and your specific preprocessing needs.\n",
    "\n",
    "User\n",
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "#neural network\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "# Assuming your images are resized to 224x224x3\n",
    "input_shape = (224, 224, 3)\n",
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers for each output\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Define the model with multiple outputs\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "this is my neural network, how to train it? and tell the errors in it\n",
    "ChatGPT\n",
    "Your neural network architecture looks good, but there is one issue in the training part: you need to ensure that your labels are properly prepared before feeding them into the model. Let's address that and provide a complete training example:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with the actual file name)\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assuming you have a column 'Image_Path' containing file paths to the images\n",
    "# Load and preprocess your images (replace the following with your actual image loading and preprocessing logic)\n",
    "X = np.random.randn(len(df), 224, 224, 3)\n",
    "\n",
    "# Split the dataset\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Preprocess labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Age labels (regression)\n",
    "scaler = StandardScaler()\n",
    "train_age_labels = scaler.fit_transform(train_df['Age'].values.reshape(-1, 1))\n",
    "val_age_labels = scaler.transform(val_df['Age'].values.reshape(-1, 1))\n",
    "test_age_labels = scaler.transform(test_df['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# Sex labels (binary classification)\n",
    "train_sex_labels = label_encoder.fit_transform(train_df['Sex'])\n",
    "val_sex_labels = label_encoder.transform(val_df['Sex'])\n",
    "test_sex_labels = label_encoder.transform(test_df['Sex'])\n",
    "\n",
    "# Race labels (multiclass classification)\n",
    "train_race_labels = label_encoder.fit_transform(train_df['Race'])\n",
    "val_race_labels = label_encoder.transform(val_df['Race'])\n",
    "test_race_labels = label_encoder.transform(test_df['Race'])\n",
    "\n",
    "train_race_labels_one_hot = to_categorical(train_race_labels, num_classes=5)\n",
    "val_race_labels_one_hot = to_categorical(val_race_labels, num_classes=5)\n",
    "test_race_labels_one_hot = to_categorical(test_race_labels, num_classes=5)\n",
    "\n",
    "# Define the model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Age prediction (regression)\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "\n",
    "# Sex prediction (binary classification)\n",
    "sex_output = Dense(1, activation='sigmoid', name='sex_output')(x)\n",
    "\n",
    "# Race prediction (softmax for multiclass classification)\n",
    "race_output = Dense(5, activation='softmax', name='race_output')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=[age_output, sex_output, race_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mean_squared_error', 'sex_output': 'binary_crossentropy', 'race_output': 'categorical_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'sex_output': 'accuracy', 'race_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X,  # Replace with your actual image data\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(\n",
    "    X_test,  # Replace with your actual test image data\n",
    "    {'age_output': test_age_labels, 'sex_output': test_sex_labels, 'race_output': test_race_labels_one_hot}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Age MAE:\", eval_result[1])\n",
    "print(\"Test Sex Accuracy:\", eval_result[2])\n",
    "print(\"Test Race Accuracy:\", eval_result[3])\n",
    "Replace 'your_dataset.csv' with your actual dataset file name. This code assumes you have a column 'Image_Path' containing file paths to the images. Adjust the data loading and preprocessing logic according to your specific requirements.\n",
    "\n",
    "User\n",
    "i am not able to figure out what X should be\n",
    "ChatGPT\n",
    "The variable X represents the input images that you want to use for training your model. In your case, you have image file paths stored in the 'Image_Path' column of your DataFrame (df). You need to load and preprocess these images to create the X array.\n",
    "\n",
    "Here's an example of how you can load and preprocess the images using the popular image processing library OpenCV. Make sure to install OpenCV first using pip install opencv-python.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'Image_Path' column contains file paths to the images\n",
    "image_paths = train_df['Image_Path'].values  # Replace with the actual column name\n",
    "\n",
    "# Load and preprocess the images\n",
    "X = []\n",
    "for path in image_paths:\n",
    "    # Read the image\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    # Resize the image to the required input shape (224x224 in your case)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # Append the preprocessed image to the list\n",
    "    X.append(img)\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "X = np.array(X)\n",
    "\n",
    "# Check the shape of X\n",
    "print(X.shape)\n",
    "In this example, X will be a NumPy array containing the preprocessed images. You need to adjust the preprocessing steps based on your specific requirements and the characteristics of your images.\n",
    "\n",
    "Repeat a similar process for the validation and test sets, replacing train_df with val_df and test_df, respectively.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# For validation set\n",
    "val_image_paths = val_df['Image_Path'].values\n",
    "X_val = []\n",
    "for path in val_image_paths:\n",
    "    # Load and preprocess images similar to the training set\n",
    "    # ...\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "# For test set\n",
    "test_image_paths = test_df['Image_Path'].values\n",
    "X_test = []\n",
    "for path in test_image_paths:\n",
    "    # Load and preprocess images similar to the training set\n",
    "    # ...\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "X_test = np.array(X_test)\n",
    "Now you can use X, X_val, and X_test in the training and evaluation steps of your model.\n",
    "\n",
    "User\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[69], line 19\n",
    "     16     X_val.append(img)\n",
    "     17 X_val = np.array(X_val)\n",
    "---> 19 history = model.fit(\n",
    "     20     X,  # Replace with your actual image data\n",
    "     21     {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "     22     validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "     23     epochs=10,\n",
    "     24     batch_size=32\n",
    "     25 )\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "     68     # To get the full stack trace, call:\n",
    "     69     # `tf.debugging.disable_traceback_filtering()`\n",
    "---> 70     raise e.with_traceback(filtered_tb) from None\n",
    "     71 finally:\n",
    "     72     del filtered_tb\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103, in convert_to_eager_tensor(value, ctx, dtype)\n",
    "    101     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n",
    "    102 ctx.ensure_initialized()\n",
    "--> 103 return ops.EagerTensor(value, ctx.device_name, dtype)\n",
    "\n",
    "ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).\n",
    "\n",
    "this error comes, how to correct it?\n",
    "ChatGPT\n",
    "The error you're encountering suggests that there might be an issue with the labels you're providing during the training process. Specifically, it seems like one of your labels might be of type NoneType. Let's investigate and address this issue.\n",
    "\n",
    "Here are a few steps you can take to troubleshoot and correct the problem:\n",
    "\n",
    "Check the labels:\n",
    "Print the shapes and types of your labels (train_age_labels, train_sex_labels, train_race_labels_one_hot, val_age_labels, val_sex_labels, val_race_labels_one_hot). Make sure they are all NumPy arrays with the correct shapes.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "print(\"Train Age Labels:\", train_age_labels.shape, train_age_labels.dtype)\n",
    "print(\"Train Sex Labels:\", train_sex_labels.shape, train_sex_labels.dtype)\n",
    "print(\"Train Race Labels:\", train_race_labels_one_hot.shape, train_race_labels_one_hot.dtype)\n",
    "\n",
    "print(\"Validation Age Labels:\", val_age_labels.shape, val_age_labels.dtype)\n",
    "print(\"Validation Sex Labels:\", val_sex_labels.shape, val_sex_labels.dtype)\n",
    "print(\"Validation Race Labels:\", val_race_labels_one_hot.shape, val_race_labels_one_hot.dtype)\n",
    "Handle missing values:\n",
    "If you find any missing values (None) in your labels, handle them appropriately. You may need to impute missing values or remove the corresponding data points.\n",
    "\n",
    "Ensure labels match the data:\n",
    "Make sure that the number of labels matches the number of corresponding data points in your input images (X, X_val). Ensure that the ordering of labels corresponds to the ordering of images.\n",
    "\n",
    "Once you've verified and corrected the labels, try running the training process again. If the issue persists, please provide the outputs of the label checks, and I can assist you further.\n",
    "\n",
    "User\n",
    "Train Age Labels: (18935, 1) float64\n",
    "Train Sex Labels: (18935,) int64\n",
    "Train Race Labels: (18935, 5) float32\n",
    "Validation Age Labels: (4057, 1) float64\n",
    "Validation Sex Labels: (4057,) int64\n",
    "Validation Race Labels: (4057, 5) float32\n",
    "\n",
    "this comes on executing the above code\n",
    "ChatGPT\n",
    "The shapes and types of your labels seem correct. The error might be occurring during the training process itself.\n",
    "\n",
    "To troubleshoot this, consider the following steps:\n",
    "\n",
    "Check for None or NaN values:\n",
    "Inspect your age labels (train_age_labels and val_age_labels) for any None or NaN values. If found, handle them appropriately by either removing the corresponding data points or imputing the missing values.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "print(\"Train Age Labels: NaN count -\", np.isnan(train_age_labels).sum())\n",
    "print(\"Validation Age Labels: NaN count -\", np.isnan(val_age_labels).sum())\n",
    "Ensure proper correspondence:\n",
    "Verify that the ordering of your labels corresponds correctly to the ordering of your input images (X and X_val). The number of labels should match the number of data points.\n",
    "\n",
    "Check if labels are correctly provided during training:\n",
    "Print a few labels before and during the training loop to see if they are being provided correctly.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "print(\"Train Age Labels Sample:\", train_age_labels[:5])\n",
    "print(\"Validation Age Labels Sample:\", val_age_labels[:5])\n",
    "\n",
    "history = model.fit(\n",
    "    X,  # Replace with your actual image data\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "These steps should help you identify and address the issue causing the ValueError. If the problem persists, please share the outputs of the additional checks, and I'll assist you further.\n",
    "\n",
    "User\n",
    "Train Age Labels: NaN count - 0\n",
    "Validation Age Labels: NaN count - 0\n",
    "ChatGPT\n",
    "Since there are no NaN values in your age labels, let's further investigate the issue. It seems like the problem might be related to how the data is being passed during the training process. Let's make sure that the labels are correctly provided during the training loop.\n",
    "\n",
    "Here's an updated version of the training loop with added print statements to help identify where the problem might be occurring:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "history = model.fit(\n",
    "    X,  # Replace with your actual image data\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "Please run this training loop, and check the output for any error messages or anomalies. Additionally, look for any patterns or specific epochs where the error occurs.\n",
    "\n",
    "If the issue persists, you might consider the following:\n",
    "\n",
    "Double-check that the shape and type of your input data (X, X_val) match the expectations of your model.\n",
    "Ensure that the ordering of images in your input data corresponds correctly to the ordering of labels.\n",
    "Feel free to share any relevant output or error messages, and I'll do my best to assist you further.\n",
    "\n",
    "User\n",
    "ValueError                                Traceback (most recent call last)\n",
    "Cell In[72], line 19\n",
    "     16     X_val.append(img)\n",
    "     17 X_val = np.array(X_val)\n",
    "---> 19 history = model.fit(\n",
    "     20     X,  # Replace with your actual image data\n",
    "     21     {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "     22     validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "     23     epochs=10,\n",
    "     24     batch_size=32\n",
    "     25 )\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "     68     # To get the full stack trace, call:\n",
    "     69     # `tf.debugging.disable_traceback_filtering()`\n",
    "---> 70     raise e.with_traceback(filtered_tb) from None\n",
    "     71 finally:\n",
    "     72     del filtered_tb\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103, in convert_to_eager_tensor(value, ctx, dtype)\n",
    "    101     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n",
    "    102 ctx.ensure_initialized()\n",
    "--> 103 return ops.EagerTensor(value, ctx.device_name, dtype)\n",
    "\n",
    "ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).\n",
    "\n",
    "this error comes again\n",
    "ChatGPT\n",
    "It seems like the error is persisting, and the issue might be related to the data provided during the training loop. Let's try a different approach to feed the data to the model. Instead of providing separate dictionaries for each output, we can create separate lists for each output during the training loop.\n",
    "\n",
    "Here's an updated version of the training loop:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "history = model.fit(\n",
    "    X,  # Replace with your actual image data\n",
    "    [train_age_labels, train_sex_labels, train_race_labels_one_hot],\n",
    "    validation_data=(X_val, [val_age_labels, val_sex_labels, val_race_labels_one_hot]),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "This way, we are providing separate lists for each output. Please try running this and see if the issue persists.\n",
    "\n",
    "If the problem continues, it might be helpful to check the data types and shapes of all your inputs and labels to ensure they align with the expectations of your model. Also, double-check that the ordering of images in your input data (X, X_val) corresponds correctly to the ordering of labels.\n",
    "\n",
    "Feel free to share any relevant output or error messages, and I'll do my best to assist you further.\n",
    "\n",
    "User\n",
    "should i provide X with:\n",
    "X = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "ChatGPT\n",
    "Yes, your code for loading the images into the X array looks correct. You are using OpenCV (cv2) to read the images and then appending them to the list. After loading all the images, you convert the list to a NumPy array.\n",
    "\n",
    "Here's your code for reference:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "X = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "This assumes that the images are correctly loaded, and the resulting X array should have the shape (num_samples, height, width, channels).\n",
    "\n",
    "Make sure that the shape of X aligns with the input shape expected by your model. If your model is designed to take images of size (224, 224, 3), then you need to resize your images to this size before feeding them to the model. You can do this by adding a resizing step inside your loop:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "X = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "This ensures that all your images have the correct size before being used as input to the model.\n",
    "\n",
    "After making sure that X is correctly prepared, you can use it as follows:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "history = model.fit(\n",
    "    X,\n",
    "    [train_age_labels, train_sex_labels, train_race_labels_one_hot],\n",
    "    validation_data=(X_val, [val_age_labels, val_sex_labels, val_race_labels_one_hot]),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "This should address the issue you were facing. If you encounter any further problems or have additional questions, feel free to ask!\n",
    "\n",
    "User\n",
    "Cell In[73], line 19\n",
    "     16     X_val.append(img)\n",
    "     17 X_val = np.array(X_val)\n",
    "---> 19 history = model.fit(\n",
    "     20     X,\n",
    "     21     [train_age_labels, train_sex_labels, train_race_labels_one_hot],\n",
    "     22     validation_data=(X_val, [val_age_labels, val_sex_labels, val_race_labels_one_hot]),\n",
    "     23     epochs=10,\n",
    "     24     batch_size=32\n",
    "     25 )\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "     68     # To get the full stack trace, call:\n",
    "     69     # `tf.debugging.disable_traceback_filtering()`\n",
    "---> 70     raise e.with_traceback(filtered_tb) from None\n",
    "     71 finally:\n",
    "     72     del filtered_tb\n",
    "\n",
    "File ~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103, in convert_to_eager_tensor(value, ctx, dtype)\n",
    "    101     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n",
    "    102 ctx.ensure_initialized()\n",
    "--> 103 return ops.EagerTensor(value, ctx.device_name, dtype)\n",
    "\n",
    "ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType).\n",
    "\n",
    "this again\n",
    "ChatGPT\n",
    "It seems that the issue persists, and the error is related to converting a NumPy array to a Tensor due to an unsupported object type (NoneType). Let's try a different approach to ensure compatibility between the data types.\n",
    "\n",
    "Firstly, make sure that your labels (train_age_labels, train_sex_labels, train_race_labels_one_hot, val_age_labels, val_sex_labels, val_race_labels_one_hot) are all valid NumPy arrays with no None values.\n",
    "\n",
    "Secondly, modify the way you load and preprocess your images. Ensure that you resize the images to the appropriate dimensions before creating the NumPy array. Here's a revised version of loading images:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "X = []\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)\n",
    "After making these changes, try running the training loop again:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "history = model.fit(\n",
    "    X,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "This approach uses separate dictionaries for each output during training.\n",
    "\n",
    "If the problem persists, it might be useful to print and inspect the data types and shapes of your input data (X) and labels to identify any mismatches or anomalies. Feel free to share the outputs or ask for further assistance.\n",
    "\n",
    "User\n",
    "import numpy as np\n",
    "# Load and preprocess the images\n",
    "X = []\n",
    "for index, row in train_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X = np.array(X)\n",
    "\n",
    "#for val set\n",
    "X_val = []\n",
    "for index, row in val_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X_val.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X_val = np.array(X_val)\n",
    "\n",
    "history = model.fit(\n",
    "    X,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "this is the code I used to train the model and it worked well, give me a code to plot the loss and accuracy plots\n",
    "ChatGPT\n",
    "Certainly! You can use the history object returned by the fit function to access the training and validation loss, as well as any specified metrics. Here's an example code to plot loss and accuracy:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by the fit function\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "train_acc = history.history['sex_output_accuracy']  # Assuming 'accuracy' is a specified metric during model compilation\n",
    "val_acc = history.history['val_sex_output_accuracy']\n",
    "\n",
    "# Plotting Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "This code uses the matplotlib library to create a subplot with two plots: one for loss and one for accuracy. Adjust the plot labels, titles, and legends as needed.\n",
    "\n",
    "Make sure to replace 'sex_output_accuracy' with the specific name of the accuracy metric you specified during the model compilation ('accuracy' in your case).\n",
    "\n",
    "Run this code after training your model, and it will display the loss and accuracy plots.\n",
    "\n",
    "User\n",
    "i have tested my model using:\n",
    "# For test set\n",
    "X_test = []\n",
    "for index, row in test_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X_test.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(\n",
    "    X_test,  # Replace with your actual test image data\n",
    "    {'age_output': test_age_labels, 'sex_output': test_sex_labels, 'race_output': test_race_labels_one_hot}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Age MAE:\", eval_result[1])\n",
    "print(\"Test Sex Accuracy:\", eval_result[2])\n",
    "print(\"Test Race Accuracy:\", eval_result[3])\n",
    "\n",
    "but now I want to save the model and check it with a random image that I give, how to do it, also include the resizing, scaling of the random image in code\n",
    "ChatGPT\n",
    "To save your trained model and make predictions on new, unseen data, you can follow these steps:\n",
    "\n",
    "Save the Model:\n",
    "python\n",
    "Copy code\n",
    "# Save the entire model to a file\n",
    "model.save('your_model.h5')\n",
    "Load the Model:\n",
    "python\n",
    "Copy code\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('your_model.h5')\n",
    "Make Predictions:\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'your_image.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(input_data)\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "Ensure you replace 'your_model.h5' with the actual filename you used when saving the model, and replace 'your_image.jpg' with the path to the image you want to test.\n",
    "\n",
    "This code assumes that your model has three output layers: age, sex, and race. Adjust the output extraction accordingly based on your model's architecture.\n",
    "\n",
    "Remember to adjust the preprocessing steps based on the preprocessing you applied during training (e.g., resizing, scaling). The example code assumes resizing to 224x224 pixels and scaling pixel values between 0 and 1. Adjust these parameters based on your model's requirements.\n",
    "\n",
    "User\n",
    "also i need to show the image before predictions in the output using matplotlib\n",
    "ChatGPT\n",
    "Certainly! You can modify the code to display the input image before making predictions using matplotlib. Here's an updated version:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'your_image.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    # Display the input image\n",
    "    plt.imshow(cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "This code adds a matplotlib plot to display the input image before making predictions. Adjust the input image path accordingly. The plt.show() function will display the image before showing the predicted values.\n",
    "\n",
    "User\n",
    "C:\\Users\\whyis\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
    "  saving_api.save_model(\n",
    "\n",
    "this comes on saving the model as u said\n",
    "ChatGPT\n",
    "The warning you're seeing is advising you to use the native Keras format (.h5 or .keras) instead of the HDF5 format when saving your model. The recommended approach is to use the .keras extension for saving models.\n",
    "\n",
    "Here's how you can modify the code to save the model with the .keras extension:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Save the entire model to a file with .keras extension\n",
    "model.save('your_model.keras')\n",
    "So, in your case, update the save line to:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "model.save('your_model.keras')\n",
    "This should resolve the warning. The .keras format is more modern and aligned with Keras best practices.\n",
    "\n",
    "User\n",
    "error                                     Traceback (most recent call last)\n",
    "Cell In[92], line 20\n",
    "     16 input_data = preprocess_image(image_path)\n",
    "     18 if input_data is not None:\n",
    "     19     # Display the input image\n",
    "---> 20     plt.imshow(cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB))\n",
    "     21     plt.title('Input Image')\n",
    "     22     plt.axis('off')\n",
    "\n",
    "error: OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xd7777888::Set<3,4,-1>,struct cv::impl::A0xd7777888::Set<0,2,5>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n",
    "> Unsupported depth of input image:\n",
    ">     'VDepth::contains(depth)'\n",
    "> where\n",
    ">     'depth' is 6 (CV_64F)\n",
    "\n",
    "this error comes as I try to test the random image, how to correct it?\n",
    "ChatGPT\n",
    "The error you're encountering suggests that the input image's depth is not supported for the conversion using cv2.cvtColor. The cv2.cvtColor function expects the input image to have a specific data type (e.g., uint8), and it seems that the input image has a depth of CV_64F (64-bit floating-point).\n",
    "\n",
    "To resolve this, you can convert the input image to the correct data type before displaying it. You can do this by converting the pixel values to the uint8 data type. Here's an updated version of the code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'your_image.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    # Display the input image\n",
    "    plt.imshow((input_data * 255).astype(np.uint8))  # Convert to uint8 before displaying\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "This modification should address the issue by ensuring that the image is displayed with the correct data type.\n",
    "\n",
    "User\n",
    "this shows the image in bgr colors, isn't their a way to see it in original colors?\n",
    "ChatGPT\n",
    "Certainly! If your original image is in RGB format and OpenCV reads it in BGR format, you can convert it back to RGB for display. Here's the modified code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'your_image.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    # Convert BGR to RGB for display\n",
    "    input_data_rgb = cv2.cvtColor(input_data, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the input image\n",
    "    plt.imshow((input_data_rgb * 255).astype(np.uint8))  # Convert to uint8 before displaying\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "Now, cv2.cvtColor is used to convert the image from BGR to RGB before displaying it using plt.imshow. This should show the image with its original colors.\n",
    "\n",
    "User\n",
    "how to use sigmoid function in jupyter notebook\n",
    "ChatGPT\n",
    "In a Jupyter Notebook, you can use the sigmoid function in various ways, depending on your needs. Here are a few approaches:\n",
    "\n",
    "Using NumPy\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Example usage\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = sigmoid(x)\n",
    "\n",
    "# Plot the sigmoid function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sigmoid(x)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "In this example, linspace creates an array of values from -5 to 5, and the sigmoid function is applied to each value. The result is then plotted using Matplotlib.\n",
    "\n",
    "Using TensorFlow (if installed)\n",
    "python\n",
    "Copy code\n",
    "import tensorflow as tf\n",
    "\n",
    "# Example usage\n",
    "x_tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "y_tensor = tf.math.sigmoid(x_tensor)\n",
    "\n",
    "# Print the result\n",
    "print(y_tensor.numpy())\n",
    "If you have TensorFlow installed, you can use the tf.math.sigmoid function directly on TensorFlow tensors.\n",
    "\n",
    "Using PyTorch (if installed)\n",
    "python\n",
    "Copy code\n",
    "import torch\n",
    "\n",
    "# Example usage\n",
    "x_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "y_tensor = torch.sigmoid(x_tensor)\n",
    "\n",
    "# Print the result\n",
    "print(y_tensor.numpy())\n",
    "If you have PyTorch installed, you can use the torch.sigmoid function directly on PyTorch tensors.\n",
    "\n",
    "Choose the approach that fits your environment and requirements. If you don't have TensorFlow or PyTorch installed and want a simple solution, the NumPy example should work well.\n",
    "\n",
    "User\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return img  # Add batch dimension\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'Divyansh Photo.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    input_data_rgb = cv2.cvtColor(input_data.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    # Display the input image\n",
    "    plt.imshow((input_data * 255).astype(np.uint8))\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "\n",
    "this code shows sex prediction as 0.211 where 0 is male and 1 is female; how to round off this?\n",
    "ChatGPT\n",
    "You can round off the sex prediction to either 0 or 1 based on a threshold value. For example, you can consider predictions greater than or equal to 0.5 as female (1) and predictions less than 0.5 as male (0). Here's how you can modify the code:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Threshold for rounding off predictions\n",
    "sex_threshold = 0.5\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'Divyansh Photo.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    input_data_rgb = cv2.cvtColor(input_data.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    # Display the input image\n",
    "    plt.imshow((input_data * 255).astype(np.uint8))\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    \n",
    "    # Round off the sex prediction\n",
    "    sex_prediction = round(predictions[1][0])\n",
    "\n",
    "    race_prediction = predictions[2][0]\n",
    "\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    print(\"Predicted Sex (0: Male, 1: Female):\", sex_prediction)\n",
    "    print(\"Predicted Race (0: White, 1: Black, 2: Asian, 3: Indian, 4: Others):\", np.argmax(race_prediction))\n",
    "else:\n",
    "    print(\"Error loading image.\")\n",
    "Adjust the sex_threshold value as needed based on your model's performance and the desired sensitivity of the prediction.\n",
    "\n",
    "User\n",
    "my model is giving predicted age between -1 and 1 , what could be the reason?\n",
    "ChatGPT\n",
    "Predicted age values between -1 and 1 could be a result of the activation function used in the output layer of your model. If you are using a linear activation function for the age prediction, it allows the model to output values in any range, including negative values.\n",
    "\n",
    "To address this issue, you may consider the following:\n",
    "\n",
    "Activation Function for Age Prediction:\n",
    "Ensure that the activation function for the age output layer is appropriate for regression tasks. Common choices include 'linear' (for unbounded regression) or 'relu' (for non-negative regression).\n",
    "\n",
    "python\n",
    "Copy code\n",
    "age_output = Dense(1, activation='linear', name='age_output')(x)\n",
    "or\n",
    "\n",
    "python\n",
    "Copy code\n",
    "age_output = Dense(1, activation='relu', name='age_output')(x)\n",
    "Choose the one that best suits your problem.\n",
    "\n",
    "Normalization of Age Labels:\n",
    "Make sure your age labels in the training data are properly normalized to be within the same range as your model's predictions. If your age labels are in the range [0, 1], the model may learn to predict values within this range.\n",
    "\n",
    "Loss Function:\n",
    "Ensure that the loss function used for age prediction is suitable for regression tasks. For example, 'mean_squared_error' is a common choice for regression problems.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'age_output': 'mean_squared_error', ...},\n",
    "    metrics={'age_output': 'mae', ...}\n",
    ")\n",
    "Adjusting these aspects should help ensure that your model predicts age values in a reasonable range. Additionally, double-check your preprocessing steps to make sure there are no unintended scaling issues with the input data.\n",
    "\n",
    "User\n",
    "i also want to plot the test accuracy and loss along with test and validation\n",
    "ChatGPT\n",
    "To plot the training and validation loss and accuracy during training, you can use the history object returned by the fit method. The history object contains the training metrics for each epoch. Here's an example of how you can plot the training and validation loss and accuracy:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and obtain the history object\n",
    "history = model.fit(\n",
    "    X,\n",
    "    {'age_output': train_age_labels, 'sex_output': train_sex_labels, 'race_output': train_race_labels_one_hot},\n",
    "    validation_data=(X_val, {'age_output': val_age_labels, 'sex_output': val_sex_labels, 'race_output': val_race_labels_one_hot}),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['sex_output_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_sex_output_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7ec5a",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ec57eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test set\n",
    "X_test = []\n",
    "for index, row in test_df.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join('resized_full_data',row['Filename'])\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            X_test.append(img)\n",
    "    except:\n",
    "        print(\"Some issue with file! \",e)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "eval_result = model.evaluate(\n",
    "    X_test,  # Replace with your actual test image data\n",
    "    {'age_output': test_age_labels, 'sex_output': test_sex_labels, 'race_output': test_race_labels_one_hot}\n",
    ")\n",
    "\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Age MAE:\", eval_result[1])\n",
    "print(\"Test Sex Accuracy:\", eval_result[2])\n",
    "print(\"Test Race Accuracy:\", eval_result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d360ac0",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2c4379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a file\n",
    "model.save('Gender-Age-Race-Prediction.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382a749",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9d10ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the saved model\n",
    "loaded_model = load_model('Gender-Age-Race-Prediction.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3819c94",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7a4cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess a single image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))  # Resize the image to match the model's input size\n",
    "        img = img / 255.0  # Scale pixel values\n",
    "        return img  # Add batch dimension\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example: Replace 'your_image.jpg' with the path to your own image\n",
    "image_path = 'peeyush image.jpg'\n",
    "input_data = preprocess_image(image_path)\n",
    "\n",
    "if input_data is not None:\n",
    "    input_data_rgb = cv2.cvtColor(input_data.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    # Display the input image\n",
    "    plt.imshow((input_data * 255).astype(np.uint8))\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predictions = loaded_model.predict(np.expand_dims(input_data, axis=0))\n",
    "\n",
    "    # Extracting predictions for each output\n",
    "    age_prediction = predictions[0][0]\n",
    "    sex_prediction = predictions[1][0]\n",
    "    race_prediction = predictions[2][0]\n",
    "    sex_threshold = 0.5\n",
    "    print(\"Predicted Age:\", age_prediction)\n",
    "    if sex_prediction<0.5:\n",
    "        print(\"Predicted Gender:\",\"Male\")\n",
    "    else:\n",
    "        print(\"Predicted Gender:\",\"Female\")\n",
    "    if np.argmax(race_prediction)==0:\n",
    "        print(\"Predicted Race: White\")\n",
    "    elif np.argmax(race_prediction)==1:\n",
    "        print(\"Predicted Race: Black\")\n",
    "    elif np.argmax(race_prediction)==2:\n",
    "        print(\"Predicted Race: Asian\")\n",
    "    elif np.argmax(race_prediction)==3:\n",
    "        print(\"Predicted Race: Indian\")\n",
    "    else:\n",
    "        print(\"Others (Not an Indian/Asian/Black/White)\")\n",
    "else:\n",
    "    print(\"Error loading image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee054595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
